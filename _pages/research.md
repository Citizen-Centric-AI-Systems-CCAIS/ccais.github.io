---
title: "Research | Citizen-Centric AI Systems | University of Southampton"
layout: textlay
excerpt: "Research | Citizen-Centric AI Systems | University of Southampton"
sitemap: false
permalink: /research/
---

# Research

AI holds great promise in addressing grand societal challenges, including the development of a smarter, cleaner electricity grid, the seamless provision of convenient on-demand mobility services, and the ability to protect citizens through advice and informed deployment of medical, emergency and police resources to fight epidemics, deal with crises and prevent crime. However, these promises can only be realised if citizens are able to trust AI systems.

In this project, we will develop the fundamental science needed to build trusted (and trustworthy) citizen-centric AI systems. These AI systems will put citizens at their heart, rather than view them as passive providers of data. They will make decisions that maximise the benefit for citizens, given their individual constraints and preferences. They will use incentives where appropriate to encourage positive behaviour change, but they will also be robust to strategic manipulation, in order to prevent individuals from exploiting the system at the expense of others. Importantly, citizen-centric AI systems will involve citizens and other stakeholders in a feedback loop that enables them to audit decisions and modify the system's behaviour to ensure that effective but also ethical decisions are taken.

Achieving our vision of citizen-centric AI systems requires several novel advances in the area of artificial intelligence.

First, to safeguard the privacy of individuals, new approaches to understanding the constraints and preferences of citizens are needed. These approaches will be distributed in nature - that is, they will not depend on collecting detailed data from individuals but will allow citizens to manage and retain their own data. To achieve this, we will develop intelligent software agents that act on behalf of each citizen, that store personal data locally and only communicate limited information to others when necessary.

Second, to incentivise positive behaviour modifications and discourage exploitation, we will draw on the field of mechanism design to model how self-interested decision-makers behave in strategic settings and how beneficial actions can be incentivised. A particular challenge will be to deal with limited information, uncertainty about preferences and a constantly changing environment that necessitates incentives to be dynamically adapted via appropriate learning mechanisms.

Finally, to enable an inclusive feedback loop involving citizens and other stakeholders, new interaction mechanisms are needed that can provide explanations for actions as well as information about whether the system is making fair decisions. While there is a wealth of emerging work on explainability and fairness in AI, this typically deals with simple one-shot problems. In contrast, we will consider more realistic and complex sequential settings, where actions have long-term consequences (including fairness) that may not be immediately apparent.